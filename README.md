# BasicNeuralNetworksCMPE258

---

```markdown
# ğŸ§  Deep Learning From Scratch â€“ Multi-Framework Nonlinear Regression

## ğŸ¯ Assignment Overview

This project implements a **3-layer deep neural network for nonlinear regression** using multiple frameworks:  
**NumPy, PyTorch (manual, class-based, Lightning), and TensorFlow (low-level, Sequential, Functional)**.

We use a custom 3-variable nonlinear function and train all networks to approximate it using synthetic data.

ğŸ“… **Due Date:** March 6  
ğŸ“Œ **Points:** 100  
ğŸ¥ **Video:** Full walkthrough of all Colabs [ğŸ“º Watch here](https://youtube.com/your-final-video-link)

---

## ğŸ§ª Problem Statement

Train a deep neural network to approximate this nonlinear function:

\[
\text{target} = \sin(x) \cdot \log(y + 1) + x^2 - y \cdot z
\]

- **Input Variables:** \(x, y, z\)  
- **Target:** Nonlinear continuous value  
- **Goal:** Approximate target using a 3-layer neural network  
- **Bonus:** 4D plot showing how inputs relate to output

---

## ğŸ“ Colab Notebooks

| Colab ID | Title | Framework | Description |
|----------|-------|-----------|-------------|
| [C1](https://colab.research.google.com/drive/1Iz6xwR_9XuEcQg80Lg0wHH_6fBAYmm7D?usp=sharing) | NumPy From Scratch | NumPy | Manual 3-layer NN using custom backpropagation and chain rule |
| [C2](https://colab.research.google.com/drive/1yMGM6MnpSieRpVXwiUY1zpGJ9j6ZA9mP?usp=sharing) | PyTorch Manual | PyTorch | Uses autograd, manual weight updates, no built-in layers |
| [C3](https://colab.research.google.com/drive/1GAKD7rg7lPmfudKluOai6JH-QMEVGinh?usp=sharing) | PyTorch Class-Based | PyTorch | Clean class-based `nn.Module` implementation |
| [C4](https://colab.research.google.com/drive/1kkZO7kkpjV7LBfEdEz_4x_6YtYzmFr-P?usp=sharing) | PyTorch Lightning | Lightning | Structured training using `LightningModule` and `Trainer` |
| [C5](https://colab.research.google.com/drive/1rB-ULg-UTUw30LMxtJiQ5v_vEEpN9XwF?usp=sharing) | TensorFlow Low-Level | TensorFlow | Uses `tf.einsum`, manual training with `GradientTape` |
| [C6](https://colab.research.google.com/drive/1FRQJDcoSPVg_yLxC4TGhrxfR_7kom_WD?usp=sharing) | TensorFlow Sequential API | TensorFlow | High-level `Sequential` model using `Dense` and `fit()` |
| [C7](https://colab.research.google.com/drive/1EBNzu-BpMERwUZRbep0MII2yB6G_42UL?usp=sharing) | TensorFlow Functional API | TensorFlow | Flexible Functional API with explicit input/output layers |

---

## ğŸ§  Model Architecture

```
Input (3D) â†’ Dense(64) â†’ ReLU â†’ Dense(32) â†’ ReLU â†’ Dense(1)
```

- Used across all frameworks for consistency  
- Ensures apples-to-apples comparison of different APIs

---

## ğŸ“Š Dataset & Visualization

- 1,000 synthetic samples of \(x, y, z\)
- Output is calculated using the custom nonlinear equation
- Colabs include 4D plots using `matplotlib` with color-coded target

---

## âœ… Requirements Covered

- âœ… Used **3-layer network** in all implementations
- âœ… Used **TensorFlow `einsum`** in `C5`
- âœ… Used a **3-variable nonlinear function**
- âœ… Included **4D visualization**
- âœ… Each notebook demonstrates training loss + output
- âœ… All Colabs and explanation video are public

---

## ğŸ¥ Video Walkthrough

ğŸ”— [**Watch the full video walkthrough here**](https://youtube.com/your-final-video-link)

Covers:
- Problem explanation
- Colab-by-Colab walkthrough
- Key highlights in each implementation
- Final results and GitHub check-in proof

---

## ğŸš€ How to Run

Each notebook is self-contained:
- Open in Google Colab
- Run all cells sequentially
- Observe 4D plot and final loss curve

---

## ğŸ™Œ Author

Submitted by [Your Name]  
MS Software Engineering, San JosÃ© State University  
Spring 2025

---

```

